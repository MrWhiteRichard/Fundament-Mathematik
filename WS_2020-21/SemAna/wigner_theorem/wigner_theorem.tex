\section{Statement and proof of Wigner's Theorem}

\begin{example} \label{example:zerodim}
	Let $H_1$ and $H_2$ be Hilbert spaces where $\dim H_1 = 0$ and $g: \mathcal{P}(H_1) \to \mathcal{P}(H_2)$ be an isometry. As $H_1 = \{0\}$ we obtain $\mathcal{P}(H_1) = \emptyset$. Now by defining $U: H_1 \to H_2: 0 \mapsto 0$ we observe that $U$ is linear as well as antilinear and also both unitary and antiunitary. Furthermore for every $R \in \mathcal{P}(H_1)$ and every $x \in H_1$ the implication 
	\begin{align*}
		x \in R \Rightarrow Ux \in g(R)
	\end{align*} 
	is true simply because $\mathcal{P}(H_1) = \emptyset$.
\end{example}

\begin{example} \label{example:onedim}
	Let $H_1$ and $H_2$ be Hilbert sapces where $\dim H_1 = 1$ and $g: \mathcal{P}(H_1) \to \mathcal{P}(H_2)$ be an isometry. Now we have $\mathcal{P}(H_1) = \{H_1\}$ which means there exists only one ray in $\mathcal{P}(H_1)$. Now we take a normalized $x \in H_1$ and a normalized $y \in g(H_1)$ and define $U: H_1 \to H_2: \lambda x \mapsto \lambda y$ and $T: H_1 \to H_2: \lambda x \mapsto \overline{\lambda} y$. For any $\lambda, \mu \in \C$
	\begin{align*}
		(U \lambda x, U \mu x)_{H_2} = (\lambda y, \mu y)_{H_2} = \lambda \overline{\mu} \norm[H_2]{y} = \lambda \overline{\mu} = \lambda \overline{\mu} \norm[H_1]{x} = (\lambda x, \mu x)_{H_2}
	\end{align*}
	and 
	\begin{align*}
		(T\lambda x, T \mu x)_{H_2} = (\overline{\lambda} y, \overline{\mu} y)_{H_2} = \overline{\lambda} \mu \norm[H_2]{y} = \overline{\lambda} \mu = \overline{\lambda } \mu \norm[H_1]{x} = \overline{(\lambda x, \mu x)_{H_2}}.
	\end{align*}
	Hence $U$ is unitary and $T$ is antiunitary. Furthermore by definition for any ray $R \in \mathcal{P}(H)$ and any $z \in R$ we have $Uz, Tz \in g(R)$. 
\end{example}

\begin{lemma} \label{lemma:phase_adjustment_ray}
	Let $H_1$ and $H_2$ be Hilbert spaces and $g: \mathcal{P}(H_1) \to \mathcal{P}(H_2)$ be an isometry. For two vectors $x,y \in H_1$ where $(x,y)_{H_1} \neq 0$ and a normalized vector $\tilde{x} \in g(\C x)$ with $\norm[H_2]{\tilde{x}} = \norm[H_1]{x}$ there exists a unique $\tilde{y} \in g(\C y)$ that fulfills $\norm[H_2]{\tilde{y}} = \norm[H_1]{y}$ and $(v,u)_{H_2} = |(v,u)_{H_2}| $.
\end{lemma}

\begin{proof}
	We take some arbitrary vector $\tilde{w} \in g(\C y)$ with $\norm[H_2]{\tilde{w}} = \norm[H_1]{\tilde{w}}$ and define $\mu := (\tilde{w}, \tilde{x})_{H_2}$. From \eqref{eq:vector_isometry} we know that $|\mu| = |(\tilde{w},\tilde{x})_{H_2}| = |(y,x)_{H_1}| \neq 0$ and hence we know that $\mu \in \C \setminus \{0\}$. Now we know from \ref{lemma:phase_adjustment_complex} that there exists a unique $\lambda \in \C$ with $|\lambda| = 1$ such that $|\lambda \mu| = \lambda \mu$. Now we define $\tilde{y} := \lambda \tilde{w}$ and obtain
	\begin{align*}
		(\tilde{y}, \tilde{x})_{H_2} = \lambda (\tilde{w}, \tilde{x})_{H_2} = \lambda \mu = |\lambda \mu| = |\lambda (\tilde{w}, \tilde{x})_{H_2}| = |(y,x)_{H_2}|
	\end{align*}
	and $\norm[H_2]{\tilde{y}} = |\lambda| \norm[H_2]{\tilde{w}} = \norm[H_1]{y}$. 
\end{proof}


\begin{lemma} \label{lemma:aux_main}
	Let $H_1$ and $H_2$ be Hilbert spaces and $g: \mathcal{P}(H_1) \to \mathcal{P}(H_2)$ an isometry. Let $M := \{e_i \mid i \in I\}$ be an orthonormal basis and $x \in H_1 \setminus \{0\}$ with
	\begin{align*}
		x = \sum_{i \in I} \lambda_i e_i
	\end{align*} 
	and $l \in I$ with $\lambda_l \in \C \setminus \{0\}$. For every $i \in I$ let $\tilde{e}_i \in g(\C e_i)$ be a normalized vector. Then there exists a unique $\tilde{x} \in g(\C x)$ with 
	\begin{align*}
		\tilde{x} = \lambda_l \tilde{e}_l + \sum_{i \in I \setminus \{l\}} \mu_i \tilde{e}_i
	\end{align*}
	where for every $i \in I \setminus \{l\}$
	\begin{align*}
		\mu_i = (\tilde{x}, \tilde{e}_i)_{H_2} \quad \text{and} \quad |\mu_i| = |\lambda_i|.
	\end{align*}
\end{lemma}

\begin{proof}
	We first observe that for every $j \in I$ 
	\begin{align}
		\pbraces{x, e_j}_{H_1} &= \pbraces{\sum_{i \in I} \lambda_i e_i, e_j}_{H_1} = \sum_{i \in I} \lambda_i \pbraces{e_i, e_j}_{H_1} = \lambda_j \label{eq:aux_fouriercoef}
	\end{align}
	Since $\lambda_l \neq 0$ we can use \ref{lemma:phase_adjustment_ray} and we obtain a unique $\tilde{y} \in g(\C x)$ with $\norm[H_2]{\tilde{y}} = \norm[H_1]{x}$ and 
	\begin{align*}
		(\tilde{y}, \tilde{e}_l)_{H_2} = |(\tilde{y}, \tilde{e}_l)_{H_2}| = |(x, e_l)_{H_1}| = \vbraces{\lambda_l}
	\end{align*}
	whereby we also used \eqref{eq:vector_isometry}. From \ref{lemma:phase_adjustment_complex} we know there exists a normalized $\nu \in \C$ with $|\lambda_l| = |\nu \lambda_l| = \nu \lambda_l$. We define $\tilde{x} := \frac{1}{\nu} \tilde{y}$ and find
	\begin{align*}
		(\tilde{x}, \tilde{e}_l)_{H_2} = \frac{1}{\nu} (\tilde{y}, \tilde{e}_l)_{H_2} = \frac{1}{\nu} |\lambda_l| = \frac{1}{\nu} \nu \lambda_l = \lambda_l.
	\end{align*} 
	Finally, using \eqref{eq:ran_fourier}, we obtain
	\begin{align*}
		\tilde{x} = \sum_{i \in I} (\tilde{x}, \tilde{e}_i)_{H_2} \tilde{e}_i = \lambda_l \tilde{e}_l + \sum_{i \in I \setminus \{l\}} (\tilde{x}, \tilde{e}_i)_{H_2} \tilde{e}_i 
	\end{align*}
	and for every $i \in A \setminus \{l\}$ we conclude, using \eqref{eq:vector_isometry} and \eqref{eq:aux_fouriercoef}, that
	\begin{align*}
		\vbraces{(\tilde{x}, \tilde{e}_i)_{H_2}} = |(x, e_i)_{H_1}| = |\lambda_iÂ´|.
	\end{align*}
\end{proof}


\begin{lemma} \label{lemma:function_on_onb}
	Let $H_1$ and $H_2$ be Hilbert spaces with $\dim H_1 > 1$ and $g: \mathcal{P}(H_1) \to \mathcal{P}(H_2)$ an isometry. Let furthermore $M := \{e_j \mid j \in J\}$ be a non-empty orthonormal basis of $H_1$ with $q \in J$ and some normalized $\tilde{e}_q \in g(\C e_q)$  and for all $j \in J \setminus \{q\}$ the vectors $v_{qj} := \frac{1}{\sqrt{2}} (e_q + e_j)$ and $w_{qj} := \frac{1}{\sqrt{2}}(e_q + ie_j)$ and $w_{jq} := \frac{1}{\sqrt{2}}(e_j + ie_q)$. Then for every $k \in J \setminus \{q\}$ there exists a normalized $\tilde{e}_k \in g(\C e_k)$ and a normalized $\tilde{v}_{qk} \in g(\C x_{qk})$ and a normalized $\tilde{w}_{qk} \in g(\C w_{qk})$ and a normalized $\tilde{w}_{kq} \in g(\C w_{kq})$ and $\lambda_k \in \{i, -i\}$ with
	\begin{align*}
		\tilde{v}_{qk} = \frac{1}{\sqrt{2}}(\tilde{e}_{q} + \tilde{e}_k) \quad \text{and} \quad \tilde{w}_{qk} = \frac{1}{\sqrt{2}}(\tilde{e}_q + \lambda_k \tilde{e}_k) \quad \text{and} \quad \tilde{w}_{kq} = \frac{1}{\sqrt{2}} (\tilde{e}_k + \lambda_k \tilde{e}_q).
	\end{align*}
\end{lemma}

\begin{proof}
	We observe that for every $i \in J$ and every $j \in J \setminus q$ we have
	\begin{align*}
		\pbraces{v_{qj}, e_i}_{H_1} = \pbraces{\frac{1}{\sqrt{2}}(e_q + e_j), e_i}_{H_1} =
		\begin{cases}
			\frac{1}{\sqrt{2}} &, \text{if } i \in \{q,j\} \\
			0 &, \text{else}
		\end{cases}
	\end{align*}
	Hence we can use \ref{lemma:phase_adjustment_ray} and obtain $\tilde{v}_{qj} \in g(\C v_{qj})$ with
	\begin{align*}
		(\tilde{v}_{qj}, \tilde{e}_q)_{H_2} = \vbraces{(\tilde{v}_{qj}, \tilde{e}_q)_{H_2}} = \vbraces{(v_{qj}, e_q)_{H_1}} = \frac{1}{\sqrt{2}}.
	\end{align*}
	Using \ref{lemma:phase_adjustment_ray} again, we find $\tilde{e}_{j} \in g(\C e_j)$ with
	\begin{align*}
		\pbraces{\tilde{v}_{qj}, \tilde{e}_j}_{H_2} = \vbraces{\pbraces{\tilde{v}_{qj}, \tilde{e}_j}_{H_2}} = \vbraces{\pbraces{v_{qj}, e_j}_{H_1}} = \frac{1}{\sqrt{2}}.
	\end{align*}
	For all $i \in J \setminus \{q, j\}$ we obtain
	\begin{align*}
		\vbraces{\pbraces{\tilde{v}_{q,j}, \tilde{e}_i}_{H_2}} = \vbraces{\pbraces{v_{qj}, e_i}_{H_1}} = 0
	\end{align*}
	and thus when using \eqref{eq:ran_fourier} we obtain
	\begin{align*}
		\tilde{v}_{qj} = \sum_{i \in I} (\tilde{v}_{qj}, \tilde{e}_i)_{H_2} \tilde{e}_i = \frac{1}{\sqrt{2}} (\tilde{e}_q + \tilde{e}_j).
	\end{align*}
	We choose some arbitrary $k \in J$. Using \ref{lemma:aux_main} we obtain $\tilde{w}_{qj} \in g(\C w_{qj})$ and $\tilde{w}_{jq} \in g(\C w_{jq})$ with
	\begin{align*}
		\tilde{w}_{qj} = \frac{1}{\sqrt{2}}(\tilde{e}_q + \lambda_j \tilde{e}_j) \quad \text{and} \quad \tilde{w}_{jq} = \frac{1}{\sqrt{2}}(\tilde{e}_j + \lambda_{q} \tilde{e}_q)
	\end{align*}
	and $\vbraces{\lambda_q} = \vbraces{\lambda_j} = 1$. Next we find
	\begin{align*}
		\frac{1}{\sqrt{2}}\vbraces{1 + \lambda_j} &= \vbraces{\pbraces{\frac{1}{\sqrt{2}}(\tilde{e}_q + \lambda_j \tilde{e}_j), \frac{1}{\sqrt{2}} (\tilde{e}_q + \tilde{e}_j)}_{H_2}} = \vbraces{\pbraces{\tilde{w}_{qj}, \tilde{v}_{qj}}_{H_2}} \\
		&= \vbraces{\pbraces{w_{qj}, v_{qj}}_{H_1}} = \vbraces{\pbraces{\frac{1}{\sqrt{2}}(e_q + ie_j), \frac{1}{\sqrt{2}} (e_q + e_j)}_{H_1}} = \frac{1}{\sqrt{2}} \vbraces{1 + i} = 1
	\end{align*}
	and similarly $\vbraces{1 + \lambda_q} = \sqrt{2}$ thus with \ref{lemma:complex_geom} we obtain $\lambda_j, \lambda_q \in \{i, -i\}$. Now we have a look at
	\begin{align*}
		\frac{1}{2}\vbraces{\lambda_j + \overline{\lambda_q}} &= \vbraces{\pbraces{\frac{1}{\sqrt{2}}(\tilde{e}_q + \lambda_j \tilde{e}_j), \frac{1}{\sqrt{2}}(\tilde{e}_j + \lambda_{q} \tilde{e}_q)}_{H_2}} = \vbraces{\pbraces{\tilde{w}_{qj}, \tilde{w}_{jq}}_{H_2}} \\
		&= \vbraces{\pbraces{w_{qj}, w_{jq}}_{H_1}} = \vbraces{\pbraces{\frac{1}{\sqrt{2}}(e_q + i e_j), \frac{1}{\sqrt{2}}(e_j + i e_q)}_{H_1}} = \frac{1}{2}\vbraces{i - i} = 0
	\end{align*}
	and conclude that $\lambda_j = \lambda_q$ because else we would have the contradiction $1 = 0$. 
\end{proof}


\begin{example} \label{example:twodim}
	Let $H_1$ and $H_2$ be Hilbert spaces with $\dim H_1 = 2$ and $g: \mathcal{P}(H_1) \to \mathcal{P}(H_2)$ an isometry. We consider a orthonormal basis $M = {e_1, e_2}$ of $H_1$ and define
	\begin{align*}
		v := \frac{1}{\sqrt{2}}(e_1 + e_2), \qquad w_{12} := \frac{1}{\sqrt{2}}(e_1 + i e_2), \qquad  w_{21} := \frac{1}{\sqrt{2}}(e_2 + i e_1).
	\end{align*} 
	From \ref{lemma:function_on_onb} we know that there exist $\tilde{e}_1 \in g(\C e_1)$, $\tilde{e}_2 \in g(\C e_2)$, $\tilde{v} \in g(\C v)$, $\tilde{w}_{12} \in g(\C w_{12})$, $\tilde{w}_{21} \in g(\C w_{21})$ and $\lambda \in \{i, -i\}$ with
	\begin{align*}
		\tilde{v} = \frac{1}{\sqrt{2}}(\tilde{e}_1 + \tilde{e}_2), \qquad \tilde{w}_{12} = \frac{1}{\sqrt{2}}(\tilde{e}_1 + \lambda \tilde{e}_2), \qquad \tilde{w}_{21} = \frac{1}{\sqrt{2}}(\tilde{e}_2 + \lambda \tilde{e}_1)
	\end{align*} 
	If $\lambda = i$ the we define $\zeta = \id_C$ and if $\lambda = -i$ we define $\zeta$ as the complex conjugation. Either way we hae $\lambda = \zeta(i)$.
	
	Now we are ready to define $U$. First of all $U0 := 0$. For an arbitrary $z \in H_1 \setminus \{0\}$ we know there exist $\lambda_1, \lambda_2 \in \C$ with $z = \lambda_1 e_1 + \lambda_2 e_2$ and there exists $r \in \{1,2\}$ with $\lambda_r \neq 0$. We then find $s \in \{1, 2\} \setminus \{r\}$. From \ref{lemma:aux_main} we know there exists $\tilde{z} \in g(\C z)$ with 
	\begin{align*}
		\tilde{z} = \lambda_r e_r + \nu_s e_s \quad \text{where} \quad \vbraces{\nu_s} = \vbraces{\lambda_s}.
	\end{align*}
	and we define
	\begin{align*}
		Uz := \zeta(\lambda_r) \tilde{e}_r + \zeta(\nu_s) \tilde{e}_s
	\end{align*}
	We find 
	\begin{align*}
		\frac{1}{\sqrt{2}} \vbraces{\lambda_r + \nu_s} = \frac{1}{\sqrt{2}} \vbraces{\zeta(\lambda_r + \nu_s)}= \vbraces{\pbraces{\tilde{z}, \tilde{v}}_{H_2}} = \vbraces{\pbraces{z, v}_{H_1}} = \frac{1}{\sqrt{2}} \vbraces{\lambda_r + \lambda_s}
	\end{align*}
	and for $y := \frac{1}{\sqrt{2}}(e_r + ie_s)$ and $\tilde{y} := \frac{1}{\sqrt{2}} (e_r + \zeta(i) e_s)$ we find
	\begin{align*}
		\frac{1}{\sqrt{2}}\vbraces{\lambda_r - i\nu_s} &= \frac{1}{\sqrt{2}} \vbraces{\zeta(\lambda_r) + \overline{\zeta(i)} \zeta(\nu_s)}= \vbraces{\pbraces{\tilde{z}, \tilde{y}}_{H_2}} \\
		&= \vbraces{\pbraces{z, y}_{H_1}} = \vbraces{\pbraces{\lambda_r e_r + \lambda_s e_2, \frac{1}{\sqrt{2}}(e_r + ie_s)}_{H_1}} = \frac{1}{\sqrt{2}} \vbraces{\lambda_r - i\lambda_s}
	\end{align*}
	and with \ref{lemma:complex_alg} we obtain $\lambda_s = \nu_s$. Hence we know
	\begin{align*}
		Uz = \zeta(\lambda_1) \tilde{e}_1 + \zeta(\lambda_2) \tilde{e}_2.
	\end{align*}
	
	For arbitrary $a,b \in H_2$ with $a = \lambda_1 e_1 + \lambda_2 e_2$ and $b = \mu_1 e_1 + \mu_2 e_2$ we obtain
	\begin{align*}
		\pbraces{Ua, Ub}_{H_2} = \pbraces{\zeta(\lambda_1) \tilde{e}_1 + \zeta(\lambda_2) \tilde{e}_2, \zeta(\mu_1) \tilde{e}_1 + \zeta(\mu_2) \tilde{e}_2}_{H_2} = \zeta(\lambda_1 \overline{\mu_1} + \lambda_2 \overline{\mu_2}) = \zeta\pbraces{\pbraces{a, b}_{H_1}}.
	\end{align*}
\end{example}


\begin{theorem}
	Let $H_1$ and $H_2$ be Hilbert spaces and $g: \mathcal{P}(H_1) \to \mathcal{P}(H_2)$ be an isometry. Then there exists a function $U: H_1 \to H_2$ that is either linear and fulfills $(Ux, Uy)_{H_2} = (x,y)_{H_1}$ for all $x,y \in H_1$ or antilinear and fulfills $(Ux, Uy)_{H_2} = \overline{(x,y)_{H_1}}$ for all $x,y \in H_1$. Furthermore for every ray $R \in \mathcal{P}(H_1)$ the implication
	\begin{align*}
		x \in R \Rightarrow Ux \in g(R).
	\end{align*}
	holds.
\end{theorem}

\begin{proof}
	We already showed the theorem for $\dim H_1 = 0$ in \ref{example:zerodim}, for $\dim H_1 = 1$ in \ref{example:onedim} and for $\dim H_1 = 2$ in \ref{example:twodim}, hence from now on we assume $\dim H_1 > 2$. We know from \ref{lemma:onb} that there exists an orthonormal basis $M := \{e_j \mid j \in J\}$ of $H_1$. First we choose some $q \in J$ and a normalized vector $\tilde{e}_q \in g(\C e_q)$. For all distinct $r,s \in J$ we define
	\begin{align*}
		v_{rs} := \frac{1}{\sqrt{2}}(e_r + e_s) \quad \text{and} \quad w_{rs} := \frac{1}{\sqrt{2}}(e_r + ie_s).
	\end{align*}
	We know from \ref{lemma:function_on_onb} that for every $j \in J \setminus \{q\}$ there exist $\tilde{e}_j \in g(\C e_j)$, $\tilde{v}_{qj} \in g(\C v_{qj})$, $\tilde{w}_{qj} \in g(\C w_{qj})$, $\tilde{w}_{jq} \in g(\C w_{jq})$ and $\lambda_j \in \{i, -i\}$ with
	\begin{align*}
		\tilde{v}_{qj} = \frac{1}{\sqrt{2}}(e_q + e_j), \qquad \tilde{w}_{qj} = \frac{1}{\sqrt{2}}(e_q + ie_j), \qquad \tilde{w}_{jq} = \frac{1}{\sqrt{2}}(e_j + ie_q).
	\end{align*} 
	We define $\tilde{v}_{jq} := \tilde{v}_{qj}$ and arbitrarily choose distinct $k,l \in J \setminus \{q\}$ and define
	\begin{align*}
		x_{kl} := \frac{1}{\sqrt{3}}(e_q + e_k + e_l) \quad \text{and} \quad y_{kl}:= \frac{1}{\sqrt{3}}(e_q + e_k + ie_l)
	\end{align*} 
	We can now use \ref{lemma:aux_main} and know that there exists a unique $\tilde{x}_{kl} \in g(\C x_{kl})$ and a unique $\tilde{y}_{kl} \in g(\C y_{kl})$ with 
	\begin{align*}
		\tilde{w}_{kl} = \frac{1}{\sqrt{3}} \pbraces{\tilde{e}_q + \lambda_{k} \tilde{e}_k + \lambda_{l} \tilde{e}_l} \quad \text{and} \quad \tilde{y}_{kl} = \frac{1}{\sqrt{3}}(\tilde{e}_q + \mu_k \tilde{e}_k + \mu_l \tilde{e}_l)
	\end{align*}
	and $|\lambda_k| = |\lambda_l| = \vbraces{\mu_k} = \vbraces{\mu_l} = 1$. Next, we can use \ref{bullet:ran_ons} and observe that for $j \in \{k,l\}$
	\begin{align*}
		\frac{1}{\sqrt{6}} \vbraces{1 + \lambda_j} &= \vbraces{\pbraces{\frac{1}{\sqrt{3}} \pbraces{\tilde{e}_q + \lambda_k \tilde{e}_k + \lambda_l \tilde{e}_l}, \frac{1}{\sqrt{2}} \pbraces{\tilde{e}_q + \tilde{e}_j}}_{H_2}} = |(\tilde{x}_{kl}, \tilde{v}_{qj})_{H_2}| \\
		&= |(x_{kl}, v_{qj})_{H_1}| = \vbraces{\pbraces{\frac{1}{\sqrt{3}} \pbraces{e_q + e_k + e_l}, \frac{1}{\sqrt{2}} (e_q + e_j)}_{H_1}} = \frac{2}{\sqrt{6}}.
	\end{align*}
	and 
	\begin{align*}
	\frac{1}{\sqrt{6}} \vbraces{1 + \mu_j} &= \vbraces{\pbraces{\frac{1}{\sqrt{3}} \pbraces{\tilde{e}_q + \mu_k \tilde{e}_k + \mu_l \tilde{e}_l}, \frac{1}{\sqrt{2}} \pbraces{\tilde{e}_q + \tilde{e}_j}}_{H_2}} = |(\tilde{y}_{kl}, \tilde{v}_{qj})_{H_2}| \\
	&= |(y_{kl}, v_{qj})_{H_1}| = \vbraces{\pbraces{\frac{1}{\sqrt{3}} \pbraces{e_q + e_k + ie_l}, \frac{1}{\sqrt{2}} (e_q + e_j)}_{H_1}} =
	\begin{cases}
		\frac{2}{\sqrt{6}} &, \text{if } j = k \\
		\frac{\sqrt{2}}{\sqrt{6}} &, \text{if } j = l
	\end{cases} .
	\end{align*}
	Using \ref{lemma:complex_geom} we obtain $\lambda_k = \lambda_l = \mu_k = 1$ and $\mu_l \in \{i, -i\}$, thus
	\begin{align*}
		\tilde{x}_{kl} = \frac{1}{\sqrt{3}}(e_q + e_k + e_l) \quad \text{and} \quad \tilde{y}_{kl} = \frac{1}{\sqrt{3}}(e_q + e_k + \mu_l e_l)
	\end{align*}
	
	Using \ref{lemma:aux_main} again we find $\tilde{v}_{kl} \in g(\C v_{kl})$ with
	\begin{align*}
		\tilde{v}_{kl} = \frac{1}{\sqrt{2}} \pbraces{\tilde{e}_k + \lambda_l Ue_l}.
	\end{align*}
	where $|\lambda_l|= \frac{\sqrt{2}}{\sqrt{2}} = 1$. We find
	\begin{align*}
		\frac{1}{\sqrt{6}} \vbraces{1 + \overline{\lambda_l}} &= \vbraces{\pbraces{\frac{1}{\sqrt{3}} \pbraces{\tilde{e}_q + \tilde{e}_k + \tilde{e}_l}, \frac{1}{\sqrt{2}} \pbraces{\tilde{e}_k + \lambda_l \tilde{e}_l}}_{H_2}} = |(\tilde{w}_{kl}, \tilde{v}_{kl})_{H_2}| \\
		&= |(w_{kl}, v_{kl})_{H_1}| = \vbraces{\pbraces{\frac{1}{\sqrt{3}} \pbraces{e_q + e_k + e_l}, \frac{1}{\sqrt{2}} (e_k + e_l)}_{H_1}} = \frac{2}{\sqrt{6}}
	\end{align*}
	and with \ref{lemma:complex_geom} we obtain $\lambda_l = 1$ and hence
	\begin{align*}
		\tilde{v}_{kl} = \frac{1}{\sqrt{2}}(\tilde{e}_k + \tilde{e}_l).
	\end{align*}
	
	For distinct $r,s \in J$ we define yet another vector
	\begin{align*}
		x_{rs} := \frac{1}{\sqrt{2}}(e_r + ie_s).
	\end{align*}
	We can use \ref{lemma:aux_main} and find a unique normalized vector $\tilde{x}_{rs} \in g(\C v_{rs})$ with
	\begin{align*}
		\tilde{x}_{rs} = \frac{1}{\sqrt{2}}(\tilde{e}_r + \lambda_{rs} \tilde{e}_s)
	\end{align*}
	and $|\mu_{\alpha \beta}| = \frac{\sqrt{3}}{\sqrt{3}} = 1$ only this time
	\begin{align*}
		\frac{1}{\sqrt{6}} \vbraces{1 + \overline{\mu_{\alpha \beta}}} &= \vbraces{\pbraces{\frac{1}{\sqrt{3}} \pbraces{Ue_\rho + Ue_\alpha + Ue_\beta}, \frac{1}{\sqrt{2}} \pbraces{Ue_\alpha + \mu_{\alpha \beta}Ue_\beta}}_{H_2}} = |(Uy_{\alpha \beta}, \tilde{v}_{\alpha \beta})_{H_2}| \\
		&= |(y_{\alpha \beta}, v_{\alpha \beta})_{H_1}| = \vbraces{\pbraces{\frac{1}{\sqrt{3}} \pbraces{e_\rho + e_\alpha + e_\beta}, \frac{1}{\sqrt{2}} (e_\alpha + ie_\beta)}_{H_1}} = \frac{1}{\sqrt{6}}\vbraces{1 + i} = \frac{\sqrt{2}}{\sqrt{6}}
	\end{align*}
	and with \ref{lemma:complex_geom} we find $\mu_{\alpha \beta} = i$ or $\mu_{\alpha \beta} = -i$. Having a look at
	\begin{align*}
		\frac{1}{2}\vbraces{\mu_{\alpha \beta} + \overline{\mu_{\beta \alpha}}} &= \vbraces{\pbraces{\frac{1}{\sqrt{2}}(Ue_\alpha + \mu_{\alpha \beta} Ue_\beta), \frac{1}{\sqrt{2}}(Ue_\beta + \mu_{\beta \alpha} Ue_\alpha)}} = |(\tilde{v}_{\alpha \beta}, \tilde{v}_{\beta \alpha})_{H_2}| \\
		&= |(v_{\alpha \beta}, v_{\beta \alpha})_{H_1}| = \vbraces{\pbraces{\frac{1}{\sqrt{2}}(e_\alpha + ie_\beta), \frac{1}{\sqrt{2}}(e_\beta + ie_\alpha)}_{H_1}} \\
		&= \frac{1}{2} \vbraces{ (ie_\alpha, e_\alpha)_{H_1} + (e_\beta, ie_\beta)_{H_1}} = \frac{1}{2} \vbraces{i - i} = 0
	\end{align*}
	we find $\mu_{\alpha \beta} = \mu_{\beta \alpha}$, because else we would have the contradiction $1 = 0$. We define
	\begin{align*}
		Uv_{\alpha \beta} := \tilde{v}_{\alpha \beta} = \frac{1}{\sqrt{2}}(Ue_\alpha + \mu_{\alpha \beta} Ue_\beta).
	\end{align*}
	Now we take $\gamma \in A \setminus{\alpha \beta}$ and define yet another vector
	\begin{align*}
		w_{\alpha \beta \gamma} := \frac{1}{\sqrt{3}} \pbraces{e_\alpha + ie_\beta + e_\gamma}
	\end{align*}
	and we find a unique $\tilde{w}_{\alpha \beta \gamma} \in g(\C w_{\alpha \beta \gamma})$ with
	\begin{align*}
		\tilde{w}_{\alpha \beta \gamma} = \frac{1}{\sqrt{3}} \pbraces{Ue_\alpha + \lambda_{\alpha \beta \gamma} Ue_\beta + \mu_{\alpha \beta \gamma} Ue_\gamma}.
	\end{align*}
	and $|\lambda_{\alpha \beta \gamma}| = |\mu_{\alpha \beta \gamma}| = \frac{\sqrt{3}}{\sqrt{3}} = 1$. For $\xi \in \{\beta, \gamma\}$ we have
	\begin{align*}
		\begin{rcases}
			\frac{1}{\sqrt{6}} |1 + \lambda_{\alpha \beta \gamma}| &, \text{if } \xi = \beta \\
			\frac{1}{\sqrt{6}} |1 + \mu_{\alpha \beta \gamma}| &, \text{if } \xi = \gamma
		\end{rcases}
		&= \vbraces{\pbraces{\frac{1}{\sqrt{3}} \pbraces{Ue_\alpha + \lambda_{\alpha \beta \gamma} Ue_\beta + \mu_{\alpha \beta \gamma} Ue_\gamma}, \frac{1}{\sqrt{2}} (Ue_\alpha + Ue_\xi)}_{H_2}} \\
		&= \vbraces{(\tilde{w}_{\alpha \beta \gamma}, Ux_{\alpha \xi})_{H_2}} = \vbraces{(w_{\alpha \beta \gamma}, x_{\alpha \xi})_{H_1}} \\
		&= \vbraces{\pbraces{\frac{1}{\sqrt{3}} \pbraces{e_\alpha + ie_\beta + e_\gamma}, \frac{1}{\sqrt{2}} (e_\alpha + e_\xi)}_{H_1}} = 
		\begin{cases}
			\frac{\sqrt{2}}{\sqrt{6}} &, \text{if } \xi = \beta \\
			\frac{2}{\sqrt{6}} &, \text{if } \xi = \gamma
		\end{cases}
	\end{align*}
	and thus $\mu_{\alpha \beta \gamma} = 1$ and $\lambda_{\alpha \beta \gamma} = i$ or $\lambda_{\alpha \beta \gamma} = -i$. We define
	\begin{align*}
		Uw_{\alpha \beta \gamma} := \tilde{w}_{\alpha \beta \gamma} = \frac{1}{\sqrt{3}} \pbraces{Ue_\alpha + \lambda_{\alpha \beta \gamma} Ue_\beta + Ue_\gamma}
	\end{align*}
	For $\xi \in \{\alpha, \gamma\}$ we do some further calculations and obtain
	\begin{align}
		\frac{1}{\sqrt{6}}\vbraces{\lambda_{\alpha \beta \gamma} + \overline{\mu_{\xi \beta}}}&= \vbraces{\pbraces{\frac{1}{\sqrt{3}} \pbraces{Ue_\alpha + \lambda_{\alpha \beta \gamma} Ue_\beta + Ue_\gamma}, \frac{1}{\sqrt{2}}(Ue_\xi + \mu_{\xi \beta} Ue_\beta)}} \\
		&= \vbraces{\pbraces{Uw_{\alpha \beta \gamma}, Uv_{\xi \beta}}_{H_2}} = \vbraces{\pbraces{w_{\alpha \beta \gamma}, v_{\xi \beta}}_{H_1}} \label{eq:aux_chain} \\
		&= \vbraces{\pbraces{\frac{1}{\sqrt{3}} \pbraces{e_\alpha + ie_\beta + e_\gamma}, \frac{1}{\sqrt{2}}(e_\xi + ie_\beta)}_{H_1}} = \frac{1}{\sqrt{6}} \vbraces{1 + (ie_{\beta}, ie_\beta)_{H_1}} = \frac{2}{\sqrt{6}}.
	\end{align}
	We can conclude that $\mu_{\alpha \beta} = \mu_{\gamma \beta}$ because if they were different than we would have one option to plug into \eqref{eq:aux_chain} for the contradiction $0 = \frac{2}{\sqrt{6}}$. Now, considering $\delta \in A \setminus \{\alpha, \beta, \gamma\}$ we can conclude that
	\begin{align*}
		\mu_{\alpha \beta} = \mu_{\gamma \beta} = \mu_{\beta \gamma} = \mu_{\delta \gamma} = \mu_{\gamma \delta}.
	\end{align*}
	At this point we distinguish between two cases.
	\begin{enumerate}
		\item $\mu_{\alpha \beta} = i$. Then we define $\zeta:\C \to \C: \lambda \mapsto \lambda$.
		\item $\mu_{\alpha \beta} = -i$. Then we define $\zeta:\C \to \C: \lambda \mapsto \overline{\lambda}$.
	\end{enumerate}
	
	We are ready to define $U$ on an arbitrary $x \in H_1 \setminus \{0\}$. We know that with the definition $\lambda_\xi := (x,e_\xi)_{H_1}$ for each $\xi \in A$ the equality
	\begin{align*}
		x = \sum_{\xi \in A} \lambda_\xi e_\xi
	\end{align*}
	holds. As $x \neq 0$ there exists some $\eta \in A$ with $\lambda_\eta \neq 0$ and we know from \ref{lemma:aux_main} that there exists a unique normalized $\tilde{x} \in g(\C x)$ with
	\begin{align*}
		\tilde{x} = \lambda_\eta Ue_\eta + \sum_{\xi \in A \setminus \{\eta\}} \nu_\xi Ue_\xi
	\end{align*} 
	with $|\lambda_\xi| = |\nu_\xi|$ for all $\xi \in A \setminus \{\eta\}$. We define
	\begin{align*}
		Ux := \zeta(\lambda_\eta) Ue_\eta + \sum_{\xi \in A} \zeta(\nu_\xi) Ue_\xi
	\end{align*}
	and remark that this definition is compatible with the previous definitions we made. Now we consider some $\delta \in A \setminus \{\eta\}$ and calculate
	\begin{align*}
		\frac{1}{\sqrt{2}}\vbraces{\lambda_\eta + \nu_\delta} &= \frac{1}{\sqrt{2}} \vbraces{\zeta(\lambda_\eta) + \zeta(\nu_\delta)} \\
		&= \vbraces{\pbraces{\zeta(\lambda_\eta) Ue_\eta + \sum_{\xi \in A} \zeta(\nu_\xi) Ue_\xi, \frac{1}{\sqrt{2}}(Ue_\eta + Ue_\delta)}_{H_2}} = |(Ux, Ux_{\eta \delta})_{H_2}| \\
		&= \vbraces{\pbraces{x, x_{\eta \delta}}_{H_1}} = \vbraces{\pbraces{\sum_{\xi \in A} \lambda_\xi e_\xi, \frac{1}{\sqrt{2}}(e_\eta + e_\delta)}_{H_1}} = \frac{1}{\sqrt{2}} \vbraces{\lambda_\eta + \lambda_\delta} 
	\end{align*}
	and furthermore
	\begin{align*}
		\frac{1}{\sqrt{2}}\vbraces{\lambda_\eta -i \nu_\delta} &= \frac{1}{\sqrt{2}} \vbraces{\zeta(\lambda_\eta) + \overline{\zeta(i)} \zeta(\nu_\delta)} \\
		&= \vbraces{\pbraces{\zeta(\lambda_\eta) Ue_\eta + \sum_{\xi \in A} \zeta(\nu_\xi) Ue_\xi, \frac{1}{\sqrt{2}}(Ue_\eta + \zeta(i) Ue_\delta)}_{H_2}} = |(Ux, Uv_{\eta \delta})_{H_2}| \\
		&= \vbraces{\pbraces{x, v_{\eta \delta}}_{H_1}} = \vbraces{\pbraces{\sum_{\xi \in A} \lambda_\xi e_\xi, \frac{1}{\sqrt{2}}(e_\eta + ie_\delta)}_{H_1}} = \frac{1}{\sqrt{2}} \vbraces{\lambda_\eta -i \lambda_\delta}.
	\end{align*}
	Now we can use \ref{lemma:complex_alg} and obtain $\nu_\delta = \lambda_\delta$. Now we observe that 
	\begin{align*}
		U(x) = \sum_{\xi \in A} \zeta(\lambda_\xi) Ue_\xi = \sum_{\xi \in A} \zeta\pbraces{(x, e_\xi)_{H_1}} Ue_\xi.
	\end{align*}
	Hence for arbitrary $v,w \in H_1$ we obtain
	\begin{align*}
		\pbraces{Uv, Uw}_{H_2} &= \pbraces{\sum_{\xi \in A} \zeta((v, e_\xi)_{H_2}) Ue_\xi, \sum_{\eta \in A} \zeta((w, e_\eta)_{H_1}) Ue_\eta}_{H_2} = \sum_{\xi \in A} \zeta\pbraces{(v, e_\xi)_{H_1} \overline{(w,e_\xi)}_{H_1}} \\
		&= \zeta \pbraces{\sum_{\xi \in A} (v, e_\xi)_{H_1} \overline{(w, e_\xi)_{H_1}}} = \zeta\pbraces{\pbraces{\sum_{\xi \in A} (v, e_\xi)_{H_1} e_\xi, \sum_{\eta \in A} (w, e_\eta)_{H_1} e_\eta}_{H_1}} = \zeta\pbraces{\pbraces{v, w}_{H_1}}.
	\end{align*}
\end{proof}