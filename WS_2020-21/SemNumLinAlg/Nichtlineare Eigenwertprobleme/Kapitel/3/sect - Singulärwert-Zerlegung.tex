\section{Singulärwert-Zerlegung}

Wir führen zunächst eine Singulärwert-Zerlegung von $A_0$ durch.
Dies ist eine Zerlegung der Form

\begin{gather*}
    \tilde V \Sigma \tilde W^\ast = A_0 \in \C^{N \times j}, \\
    \tilde V \in \U_N(\C),
    \quad
    \tilde W \in \U_j(\C),
    \quad
    \Sigma = \begin{pmatrix}
        \diag(\sigma_1, \dots, \sigma_J, \dots, \sigma_j) \\
        0_{(N - j) \times j}
    \end{pmatrix} \in \C^{N \times j}.
\end{gather*}

Dabei gehen wir nicht auf die technischen Details zur Bestimmung der Singulärwert-Zerlegung ein.
Wir verwenden lediglich den Befehl \texttt{linalg.svd} aus der \texttt{scipy}-Bibliothek.

Wir nehmen zunächst an, dass die Rechts- bzw. Links-Eigenraum-Basen $V, W \in \C^{N \times J}$ vollen Rang $J$ haben, und die Zufallsmatrix $\hat V \in \C^{N \times j}$ vollen Rang $j$ hat.
Weiters gehen wir davon aus, dass $W^\ast \hat V \in C^{J \times j}$ vollen Rang $J \leq j$ hat.
Das heißt, $V$ und $W^\ast \hat V$ sind injektiv, also auch deren Komposition $A_0 = V W^\ast \hat V$.
Daher ist auch die Annahme, dass $A_0$ Rang $J$ hat, sinnvoll.

Matrizen haben genau dann denselben Rang, wenn sie bzgl. $\equiv$ äquivalent sind (d.h. modulo Multiplikation mit zwei regulären Matrix von jeweils links bzw. rechts).
$\tilde V$ und $\tilde W^\ast$ sind als unitäre Matrizen regulär.
Für jede $\equiv$-Äquivalenzklasse finden wir einen Repräsentanten in einer Normalform als Blockmatrix einer Einheitsmatrix und sonst $0$-en.
Wir erhalten die Äquivalenz

\begin{align*}
    \begin{pmatrix}
        \diag(\sigma_1, \dots, \sigma_J, \dots, \sigma_j) \\
        0_{(N - j) \times j}
    \end{pmatrix}
    =
    \Sigma
    \equiv
    \tilde V \Sigma \tilde W^\ast
    =
    A_0
    \equiv
    \begin{pmatrix}
        I_J & 0_{J \times (j - J)} \\ 0_{(N - J) \times J} &0_{(N - J) \times (j - J)}
    \end{pmatrix}.
\end{align*}

Damit verschwinden die letzten Singulärwerte $\sigma_{J+1} = \cdots = \sigma_j = 0$.
Somit können wir statt der alten vollen Singulärwert-Zerlegung (jetzt indiziert mit \Quote{full}) eine reduzierte (indiziert mit \Quote{reduced}) verwenden.
Dabei bestehen $\tilde V_\mathrm{reduced}$, $\Sigma_\mathrm{reduced}$, und $\tilde W_\mathrm{reduced}$ aus den ersten $J$ Spalten von $\tilde V_\mathrm{full}$, $\Sigma_\mathrm{full}$, bzw. $\tilde W_\mathrm{full}$.
Diese beiden Singulärwert-Zerlegungen sind tatsächlich gleichwertig, weil

\begin{align*}
    A_0
    & =
    \tilde V_\mathrm{full} \Sigma_\mathrm{full} \tilde W_\mathrm{full}^\ast
    =
    \begin{pmatrix}
        \tilde V_\mathrm{reduced} & \ast
    \end{pmatrix}
    \begin{pmatrix}
        \Sigma_\mathrm{reduced} & 0_{J \times (j - J)} \\
        0_{(N - J) \times J}    & 0_{(N - J) \times (j - J)}
    \end{pmatrix}
    \begin{pmatrix}
        \tilde W_\mathrm{reduced}^\ast \\ \ast
    \end{pmatrix} \\
    & =
    \tilde V_\mathrm{reduced} \Sigma_\mathrm{reduced} \tilde W_\mathrm{reduced}^\ast.
\end{align*}

Die reduzierten Matrizen sind zwar nicht mehr unitär, aber es gilt

\begin{align*}
    I_N
    & =
    \tilde V_\mathrm{full}^\ast \tilde V_\mathrm{full}
    =
    \begin{pmatrix}
        \tilde V_\mathrm{reduced}^\ast \\ \ast
    \end{pmatrix}
    \begin{pmatrix}
        \tilde V_\mathrm{reduced} & \ast
    \end{pmatrix}
    =
    \begin{pmatrix}
        \tilde V_\mathrm{reduced}^\ast \tilde V_\mathrm{reduced} & \ast \\
        \ast                                                     & \ast
    \end{pmatrix}, \\
    I_j
    & =
    \tilde W_\mathrm{full}^\ast \tilde W_\mathrm{full}
    =
    \begin{pmatrix}
        \tilde W_\mathrm{reduced}^\ast \\ \ast
    \end{pmatrix}
    \begin{pmatrix}
        \tilde W_\mathrm{reduced} & \ast
    \end{pmatrix}
    =
    \begin{pmatrix}
        \tilde W_\mathrm{reduced}^\ast \tilde W_\mathrm{reduced} & \ast \\
        \ast                                                     & \ast
    \end{pmatrix}.
\end{align*}

Wir vereinbaren, ab sofort nur noch die reduzierte Singulärwert-Zerlegung zu verwenden und den Index wegzulassen.
Insgesamt erhalten wir also unsere reduzierte Singulärwert-Zerlegung

\begin{gather}
    A_0 = \tilde V \Sigma \tilde W^\ast, \nonumber \\
    \tilde V \in \C^{N \times J},
    \quad
    \tilde W \in \C^{j \times J},
    \quad
    \Sigma = \diag(\sigma_1, \dots, \sigma_J) \in \C^{J \times J}, \label{eq:singulaerwert_zerlegung} \\
    \tilde V^\ast \tilde V
    =
    \tilde W^\ast \tilde W
    =
    I_J \nonumber
\end{gather}

Da wir an $V$ vollen Rang vorausgesetzt haben, können wir auch annehmen, dass $S := \tilde V^\ast V \in \C^{J \times J}$ vollen Rang $J$ hat, also $\in \GL_J(\C)$, d.h. invertierbar ist.
Nun nutzen wir die Singulärwert-Zerlegung von $A_0$ und berechnen

\begin{align*}
    \Sigma \tilde W^\ast
    \stackrel
    {\eqref{eq:singulaerwert_zerlegung}}{=}
    \tilde V^\ast \tilde V \Sigma \tilde W^\ast
    \stackrel
    {
        \eqref{eq:singulaerwert_zerlegung}
    }{=}
    \tilde V^\ast A_0
    \stackrel
    {
        \eqref{eq:integral_matrizen_resultat}
    }{=}
    \tilde V^\ast V W^\ast \hat V
    =
    S W^\ast \hat V.
\end{align*}

Setzen wir in dies in die Darstellung von $A_1$ über die Konturintegrale ein, erhalten wir

\begin{align*}
    A_1
    \stackrel
    {
        \eqref{eq:integral_matrizen_resultat}
    }{=}
    V D W^\ast \hat V
    =
    V D S^{-1} \Sigma \tilde W^\ast,
\end{align*}

was uns schließlich

\begin{align*}
    \tilde V^\ast A_1 \tilde W \Sigma^{-1}
    =
    \tilde V^\ast V D S^{-1} \Sigma \tilde W^\ast \tilde W \Sigma^{-1}
    =
    S D S^{-1}
    \sim
    D
\end{align*}

liefert.

Somit ist die Diagonalmatrix $D$, welche ja die gesuchten Eigenwerte $\lambda_1, \dots, \lambda_k$ von $A$ enthält, ähnlich zur Matrix $\tilde V^\ast A_1 \tilde W \Sigma^{-1}$.
Ähnliche Matrizen haben dieselben Eigenwerte.
