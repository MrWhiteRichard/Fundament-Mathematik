\begin{exercise}

Sei $H$ ein Hilbertraum.
Zeige:
Ist $(P_n)_{n \in \N}$ eine Folge von orthogonalen Projektionen $(P_n \neq 0)$, für die gilt

\begin{align*}
  \ran P_n ~\bot~ \ran P_m, \qquad n \neq m,
\end{align*}

und ist $\alpha = (\alpha_n)_{n \in \N} \in \ell^{\infty}$, mit $\alpha_n \neq 0, n \in \N$, so ist für jedes $x \in H$ die Reihe

\begin{align*}
  Ax := \sum_{n=1}^\infty \alpha_n P_n x
\end{align*}

konvergent.
Es gilt $A \in \mathcal{B}(H), \|A\| = \norm[\infty]{\alpha}$.
Bestimme $\ker A$. Ist $\alpha_n \to 0$, so konvergiert die Reihe in der Operatornorm.
Gilt auch die Umkehrung?

\end{exercise}

\begin{solution}

Für $n \in \N$, ist $\ker{P_n}$ das orthogonale Komplement von $\ran P_n$.
Wegen $\ran{P_m} \bot \ran{P_n} \bot \ker{P_n}$ gilt also $\ran P_m \subseteq \ker P_n$.
Somit, muss $P_n P_m = 0$.

Wir wissen, dass für orthogonale Projektionen $P_1$ und $P_2$ mit dieser Eigenschaft $P_1 + P_2$ wieder eine orthogonale Projektion ist, und $\ran{(P_1 + P_2)} = \ran{P_1} + \ran{P_2}$.

Die endlichen Summen der Projektionen $(P_n)_{n \in \N}$ sind also wieder orthogonale Projektionen.

\begin{align*}
    \norm{\sum_{n = M+1}^N \alpha_n P_n x}^2
    \stackrel{(a)}{=}
    \sum_{n = M+1}^N \norm{\alpha_n P_n x}^2
    \stackrel{(b)}{=}
    \sum_{n = M+1}^N |\alpha_n|^2 \norm{P_n x}^2 \\
    \stackrel{(c)}{\leq}
    \max_{M+1 \leq n \leq N} |\alpha_n|^2 \sum_{n = M+1}^N \norm{P_n x}^2
    \stackrel{(d)}{=}
    \max_{M+1 \leq n \leq N} |\alpha_n|^2 \norm{\pbraces{\sum_{n = M+1}^N P_n} x}^2 \\
    \stackrel{(e)}{\leq}
    \max_{M+1 \leq n \leq N} |\alpha_n|^2 \norm{x}^2
    \stackrel{(f)}{\leq}
    \norm[\infty]{\alpha}^2 \norm{x}^2.
\end{align*}

(a), (d), (g) gilt laut dem Satz von Pythagoras.

(e), (h) gelten, weil die endliche Summe orthogonaler Projektionen mit der Eigenschaft $P_n P_m = 0$ wieder eine orthogonale Projektion ist, also Abbildungsnorm kleiner gleich $1$ hat. \\

Wir betrachten Folgendes nochmal genauer.

\begin{align*}
    \sum_{n = 1}^N \norm{P_n x}^2
    \stackrel{(g)}{=}
    \norm{\pbraces{\sum_{n = 1}^N P_n} x}^2
    \stackrel{(h)}{\leq}
    \norm{x}^2
\end{align*}

$\sum_{n = 1}^N \| P_n x \|^2$ ist also beschränkt, und somit absolut konvergent.

\begin{align*}
  \norm{\sum_{n = M+1}^N \alpha_n P_n x}^2
  \leq
  \max_{M+1 \leq n \leq N} |\alpha_n|^2 \norm{\pbraces{\sum_{n = M+1}^N P_n} x}^2
  \leq
  \norm[\infty]{\alpha} \norm{\pbraces{\sum_{n = M+1}^N P_n} x}^2
  \xrightarrow{M, N \rightarrow \infty} 0
\end{align*}

Dabei, haben die erste Ungleichung schon oben gezeigt.
Der Grenzübergang folgt aus (g).
Damit, ist die Reihe eine Cauchy-Folge, also konvergent. \\

\blockquote{$\norm{A} \leq \norm[\infty]{\alpha}$}:
Mit (a)-(f) gilt

\begin{align*}
    \norm[\infty]{\alpha}^2 \norm{x}^2
    \geq
    \norm{\sum_{n = 1}^N \alpha_n P_n x}^2
    \xrightarrow{N \to \infty}
    \norm{A x}^2.
\end{align*}

Also $\norm{A} \leq \norm[\infty]{\alpha}$ und somit $A \in \mathcal{B}(H)$. \\

\blockquote{$\norm{A} \geq \norm[\infty]{\alpha}$}:
Sei $(\alpha_{n(k)})_{k \in \N}$ eine Teil-Folge, sodass

\begin{align*}
  |\alpha_{n(k)}|
  \xrightarrow{k \to \infty}
  \sup_{n \in \N} |\alpha_n|
  =
  \norm[\infty]{\alpha}.
\end{align*}

Sei $\forall k \in \N: x_{n(k)} \in \ran{P_{n(k)}}$, mit $\norm{x_{n(k)}} = 1$.
$\Forall \ell \in \N \setminus \Bbraces{n(k)}:$

\begin{align*}
  P_\ell x_{n(k)} = P_\ell P_{n(k)} x_{n(k)} = 0
  \implies
  \norm{A}
  \geq
  \norm{\sum_{n=1}^\infty \alpha_n P_n x_{n(k)}}
  =
  \norm{\alpha_{n(k)} P_{n(k)} x_{n(k)}}
  =
  |\alpha_n(k)|
  \xrightarrow{k \to \infty}
  \norm[\infty]{\alpha}
\end{align*}

Wir zeigen, dass

\begin{align*}
  \bigcap_{n \in \N} \ker{P_n}
  =
  \ker{A}
  =
  \Bbraces{x \in H: A x = 0}
  =
  \Bbraces{x \in H: \sum_{n=1}^\infty \alpha_n P_n x = 0}
\end{align*}

\blockquote{$\subseteq$}:
Trivial!

\blockquote{$\supseteq$}:
Wegen dem Pythagoras, gilt $\Forall x \in \ker{A}:$

\begin{align*}
    \sum_{n=1}^N |\alpha_n|^2 \norm{P_n x}^2
    =
    \norm{\sum_{n = 1}^N \alpha_n P_n x}^2
    \xrightarrow{N \rightarrow \infty}
    \norm{A x}^2 = 0.
\end{align*}

Das ist wegen $\alpha_n \neq 0$ offenbar nur dann möglich, wenn für alle $n \in \N$, $\norm{P_n x} = 0$ ist, also $P_n x = 0$. \\

Nun zur Konvergenz in der Operatornorm.
Diese folgt, mit $\norm{x} = 1$, aus

\begin{align*}
  \norm{\sum_{n=M+1}^N \alpha_n P_n x}
  \leq
  \max_{M+1 \leq n \leq N} |\alpha_n| \norm{x}
  \xrightarrow{M, N \to \infty} 0,
\end{align*}

Weil die Linearen Abbildungen mit der Abbildungsnorm einen Banachraum bildern.
Die obere Cauchy-Folge ist also darin konvergent. \\

Die Umkehrung gilt ebenfalls.
Das zeigen wir via Kontraposition.
Sei $(\alpha_n)_{n \in \N}$ keine Nullfolge.
D.h. $\Exists \epsilon > 0, \Forall n \in \N: \Exists M, N > n, \Exists k \in \N:$

\begin{align*}
  M+1 \leq k \leq N,
  \quad
  |\alpha_k|^2 > \epsilon.
\end{align*}

Wegen $P_k \neq 0$ gibt es ein $x \in \ran{P_k} \setminus \Bbraces{0}$.
$P_k$ ist auf seinem Bild die Identität.
Damit gilt

\begin{align*}
 \norm{\sum_{n = M+1}^N \alpha_n P_n x}^2
 \stackrel{(b)}{=}
 \sum_{n = M+1}^N |\alpha_n|^2 \norm{P_n x}^2
 \geq
 |\alpha_k|^2 \norm{x}^2
 >
 \epsilon \norm{x}^2.
\end{align*}

Es liegt also keine Konvergenz in der Operatornorm vor. \\

\end{solution}
