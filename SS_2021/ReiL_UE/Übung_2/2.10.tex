% --------------------------------------------------------------------------------

\begin{exercise}[Exercise 3.7]

Imagine that you are designing a robot to run a maze.
You decide to give it a reward of $+1$ for escaping from the maze and a reward of zero at all other times.
The task seems to break down naturally into episodes - the successive runs through the maze - so you decide to treat it as an episodic task, where the goal is to maximize expected total reward \eqref{eq:2.10}.
After running the learning agent for a while, you find that it is showing no improvement in escaping from the maze.
What is going wrong?
Have you effectively communicated to the agent what you want it to achieve?

\begin{align} \label{eq:2.10}
    G_t \doteq R_{t+1} + R_{t+2} + R_{t+3} + \cdots + R_T
\end{align}

\end{exercise}

% --------------------------------------------------------------------------------

\begin{solution}

ToDo!

\end{solution}

% --------------------------------------------------------------------------------
