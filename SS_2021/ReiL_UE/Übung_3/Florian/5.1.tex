% -------------------------------------------------------------------------------- %

\begin{exercise}[Exercise 6.1]

If $V$ changes during the episode, then 

\begin{align*}
    G_t - V(S_t) = \sum_{k=t}^{T-1} \gamma^{k-t} \delta_k. \tag{6.6}
\end{align*}

only holds approximately;
what would the difference be between the two sides? Let $V_t$ denote the
array of state values used at time $t$ in the TD error

\begin{align*}
    \delta_t \doteq R_{t+1} + \gamma V_t(S_{t+1}) - V_t(S_t). \tag{6.5}
\end{align*}

and in the
TD update. 

\begin{align*}
    V_{t+1}(S_t) \leftarrow V_t(S_t) + \alpha\Big[R_{t+1} + 
    \gamma V_t(S_{t+1}) - V_t(S_t)] \tag{6.2}
\end{align*}

Redo the derivation above to determine the additional
amount that must be added to the sum of TD errors in order to equal the
Monte Carlo error.

\end{exercise}

% -------------------------------------------------------------------------------- %

\begin{solution}

\begin{align*}
    G_t - V_t(S_t) 
    &= R_{t+1} + \gamma G_{t+1} - V_t(S_t) + \gamma V_t(S_{t+1}) - \gamma V_t(S_{t+1}) \\
    &= \delta_t + \gamma (G_{t+1} - V_t(S_{t+1})) \\
    &= \delta_t + \gamma (R_{t+2} + \gamma G_{t+2} - V_t(S_{t+1})
     + \gamma V_{t+1}(S_{t+2}) - \gamma V_{t+1}(S_{t+2}) 
     + V_{t+1}(S_{t+1}) - V_{t+1}(S_{t+1})) \\
     &= \delta_t + \gamma (\delta_{t+1} + 
     \underbrace{[V_{t+1}(S_{t+1}) - V_t(S_{t+1})]}_{\doteq \epsilon_{t+1}} + 
     \gamma[G_{t+2} - V_{t+1}(S_{t+2})]) \\
     &= \delta_t + \gamma(\delta_{t+1} + \epsilon_{t+1}) + \dots
     + \gamma^{T - t}\underbrace{(G_T - V_{T-1}(S_{T}))}_{=0} \\
     &= \delta_t + \sum_{k={t+1}}^{T-1} \gamma^{k-t}(\delta_{t+1} + \epsilon_{t+1}).
\end{align*}

\end{solution}

% -------------------------------------------------------------------------------- %
