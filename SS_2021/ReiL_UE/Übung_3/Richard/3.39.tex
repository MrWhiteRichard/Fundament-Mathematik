% -------------------------------------------------------------------------------- %

\begin{exercise}[Exercise 6.11]

Why is Q-learning consider an off-policy control method?

\end{exercise}

% -------------------------------------------------------------------------------- %

\begin{solution}

Q-learning generates samples, by using the policy derived from the current $Q$, however, it updates $Q$ by virtue of maximising $Q(S^\prime, \cdot)$.
But, in the special case of choosing $\varepsilon = 1$, Q-learning is an on-policy method.

\end{solution}

% -------------------------------------------------------------------------------- %
