{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd029dd0665073eae84ffe5a7687a8a9c5d424813438214318fcc694af1c42e9e2c",
   "display_name": "Python 3.9.2 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "29dd0665073eae84ffe5a7687a8a9c5d424813438214318fcc694af1c42e9e2c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Autonomous Orchard"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Exercise"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "An AI controlled orchard needs to decide when to harvest its trees.\n",
    "To do this it measures the concentration of three chemicals in the air.\n",
    "Each day the orchard can choose to wait or harvest.\n",
    "Waiting costs one credit in operating costs while a harvest ends the process.\n",
    "Once a crop is harvested, packaged and sold, the orchard is told the profit or loss of that harvest.\n",
    "Most experts agree that the function mapping the chemical concentrations to the profit is linear with some error.\n",
    "The orchard has several samples of the profits from other harvests:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\begin{array}{|c|c|c|c|}\n",
    "        \\hline\n",
    "        \\text{Concentration of}~ A ~\\text{(ppm)} &\n",
    "        \\text{Concentration of}~ B ~\\text{(ppm)} &\n",
    "        \\text{Concentration of}~ C ~\\text{(ppm)} &\n",
    "        \\text{Profit/Rewrad (credits)} \\\\ \\hline\n",
    "        4  & 7  & 1  & 3   \\\\ \\hline\n",
    "        10 & 6  & 0  & -15 \\\\ \\hline\n",
    "        20 & 1  & 15 & 5   \\\\ \\hline\n",
    "        4  & 19 & 3  & 21  \\\\ \\hline\n",
    "    \\end{array}\n",
    "\\end{align*}\n",
    "\n",
    "Begin to approximate (by hand) the function that maps the state feature vector to $Q(\\text{state}, \\text{harvest})$ using an MC goal.\n",
    "Do a gradient decent step on each ssample.\n",
    "A sensible learning rate would be around $0.01$, but feel free to try any value."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Solution"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Preparations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from fractions import Fraction"
   ]
  },
  {
   "source": [
    "The MC gradient update reads\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathbf w_{t+1}\n",
    "    & \\doteq\n",
    "    \\mathbf w_t + \\alpha [U_t - \\hat q(S_t, A_t, \\mathbf w_t)] \\nabla \\hat q(S_t, A_t, \\mathbf w_t), \\tag{10.1}\n",
    "\\end{align}\n",
    "\n",
    "where $U_t = G_t$."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Let the state space be $\\mathbb R^3$, where the components stand for the concentrations of each chemical respectively.\n",
    "The action space is $\\{ \\texttt{harvest}, \\texttt{wait} \\}$."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Our weights $\\mathbf w$ will be initialized with $\\mathbf 0$."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = defaultdict(lambda: np.zeros(3))"
   ]
  },
  {
   "source": [
    "We assume that, immediately after the sample was taken, the fruit was harvested;\n",
    "i.e. the actions in the table are all 'harvest'."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         state   action  reward\n",
       "0    [4, 7, 1]  harvest       3\n",
       "1   [10, 6, 0]  harvest     -15\n",
       "2  [20, 1, 15]  harvest       5\n",
       "3   [4, 19, 3]  harvest      21"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>state</th>\n      <th>action</th>\n      <th>reward</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[4, 7, 1]</td>\n      <td>harvest</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[10, 6, 0]</td>\n      <td>harvest</td>\n      <td>-15</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[20, 1, 15]</td>\n      <td>harvest</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[4, 19, 3]</td>\n      <td>harvest</td>\n      <td>21</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'state': [\n",
    "        np.array([4,  7,  1]),\n",
    "        np.array([10, 6,  0]),\n",
    "        np.array([20, 1,  15]),\n",
    "        np.array([4,  19, 3])\n",
    "    ],\n",
    "    'action': ['harvest'] * 4,\n",
    "    'reward': [3, -15, 5, 21]\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01"
   ]
  },
  {
   "source": [
    "As the function $\\hat q(\\cdot, \\texttt{harvest}, \\mathbf w)$ should be linear, we can use\n",
    "\n",
    "\\begin{align}\n",
    "    \\hat q(s, a, \\mathbf w)\n",
    "    \\doteq\n",
    "    \\mathbf w^\\top \\mathbf x(s, a)\n",
    "    =\n",
    "    \\sum_{i=1}^d\n",
    "        w_i \\cdot x_i(s, a),\n",
    "\\end{align}\n",
    "\n",
    "and hence (a special case of (10.1))\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathbf w_{t+1}\n",
    "    & =\n",
    "    \\mathbf w_t + \\alpha [G_t - \\mathbf w_t^\\top \\mathbf x(S_t, A_t)] \\mathbf x(S_t, A_t),\n",
    "\\end{align}\n",
    "\n",
    "where, $d = 3$ and\n",
    "\n",
    "- $\\mathbf w_t$ ... `w[t]`,\n",
    "- $\\alpha$ ... `alpha`,\n",
    "- $G_t$ ... `df['reward'][t]`,\n",
    "- $\\mathbf x$ ... `x`,\n",
    "- $S_t$ ... `df['state'][t]`,\n",
    "- $A_t$ ... `df['action'][t]`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Perhaps the easiest way of choosing $(s, a) \\mapsto \\mathbf x(s, a)$ is simply returning the state $s$, if the action $a = \\texttt{harvest}$."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x(state, action):\n",
    "    if action == 'harvest':\n",
    "        return state\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "source": [
    "### Calculations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "w[0] = [0. 0. 0.]\n     = ['0', '0', '0']\n\nw[1] = [0.12 0.21 0.03]\n     = ['1/6', '1/5', '0']\n\nw[2] = [-1.626  -0.8376  0.03  ]\n     = ['-8/5', '-5/6', '0']\n\nw[3] = [ 5.95552  -0.458524  5.71614 ]\n     = ['6', '-1/2', '23/4']\n\nw[4] = [ 5.50517824 -2.59764736  5.37838368]\n     = ['11/2', '-13/5', '27/5']\n\n"
     ]
    }
   ],
   "source": [
    "print(f'w[{0}] = {w[0]}')\n",
    "print(f'     = {[str(Fraction(w_).limit_denominator(6)) for w_ in w[0]]}')\n",
    "print()\n",
    "\n",
    "for t in range(4):\n",
    "\n",
    "    w[t+1] = w[t] + alpha * (df['reward'][t] - w[t] @ x(df['state'][t], df['action'][t])) * x(df['state'][t], df['action'][t])\n",
    "    print(f'w[{t+1}] = {w[t+1]}')\n",
    "    print(f'     = {[str(Fraction(w_).limit_denominator(6)) for w_ in w[t+1]]}')\n",
    "    print()"
   ]
  }
 ]
}