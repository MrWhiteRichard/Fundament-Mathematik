{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation on Github: https://github.com/openai/gym/blob/master/gym/envs/classic_control/mountain_car.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.reset()\n",
    "#for _ in range(1000):\n",
    "#    env.render()\n",
    "#    env.step(env.action_space.sample()) # take a random action\n",
    "#env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class agent:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.env = gym.make(\"CartPole-v0\")\n",
    "        self.env.reset()\n",
    "        \n",
    "    def select_action(self,theta):\n",
    "        action_list = self.env.action_space\n",
    "        weights = [policy(self.env.state, action, action_list, theta) for action in get_space_list(action_list)]\n",
    "        return np.random.choice([action for action in get_space_list(action_list)],p = weights)\n",
    "        \n",
    "    def Reinforce(self, alpha, gamma, nr_episodes):\n",
    "        theta = np.zeros(len(feature_vector(self.env.state,self.env.action_space.sample())))\n",
    "        \n",
    "        for k in range(nr_episodes):\n",
    "            self.env.reset()\n",
    "            S = [self.env.state]\n",
    "            a = self.select_action(theta)\n",
    "            A = [a]\n",
    "            R = []\n",
    "            new_state, reward, boolean,klam = self.env.step(a)\n",
    "            S.append(new_state)\n",
    "            R.append(reward)\n",
    "            \n",
    "            while not boolean:\n",
    "                a = self.select_action(theta)\n",
    "                A.append(a)\n",
    "                new_state, reward, boolean, klam = self.env.step(a)\n",
    "                S.append(new_state)\n",
    "                R.append(reward)\n",
    "            \n",
    "            for t in range(len(A)):\n",
    "                G = 0\n",
    "                for j in range(t,len(A)):\n",
    "                    G += gamma**(j-t-1)*R[j]\n",
    "                gradient = (\n",
    "                    feature_vector(S[t],A[t])-\n",
    "                    sum([policy(S[t],b,self.env.action_space,theta)*feature_vector(S[t],b) for b in get_space_list(self.env.action_space)],0)\n",
    "                )\n",
    "                theta += alpha*(gamma**t)*G*gradient\n",
    "        return theta\n",
    "    \n",
    "    \n",
    "def policy(state,action,action_space,theta):\n",
    "    denom = sum([np.exp(theta@feature_vector(state,a)) for a in get_space_list(action_space)],0)\n",
    "    return np.exp(theta@feature_vector(state,action))/denom   \n",
    "    \n",
    "def feature_vector(state, action):\n",
    "    s = state\n",
    "    x = np.array([1,s[0],s[1],s[2],s[3],s[0]*s[1],s[0]*s[2],s[0]*s[3],s[1]*s[2],s[1]*s[3],s[2]*s[3], action])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_space_list(space):\n",
    "\n",
    "    \"\"\"\n",
    "    Converts gym space, constructed from types, to list space_list\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------------- #\n",
    "\n",
    "    types = [\n",
    "        gym.spaces.multi_binary.MultiBinary,\n",
    "        gym.spaces.discrete.Discrete,\n",
    "        gym.spaces.multi_discrete.MultiDiscrete,\n",
    "        gym.spaces.dict.Dict,\n",
    "        gym.spaces.tuple.Tuple,\n",
    "    ]\n",
    "\n",
    "    if type(space) not in types:\n",
    "        raise ValueError(f'input space {space} is not construdted from spaces of types:' + '\\n' + str(types))\n",
    "\n",
    "    # -------------------------------- #\n",
    "\n",
    "    if type(space) is gym.spaces.multi_binary.MultiBinary:\n",
    "        return [\n",
    "            np.reshape(np.array(element), space.n)\n",
    "            for element in itertools.product(\n",
    "                *[range(2)] * np.prod(space.n)\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    if type(space) is gym.spaces.discrete.Discrete:\n",
    "        return list(range(space.n))\n",
    "\n",
    "    if type(space) is gym.spaces.multi_discrete.MultiDiscrete:\n",
    "        return [\n",
    "            np.array(element) for element in itertools.product(\n",
    "                *[range(n) for n in space.nvec]\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    if type(space) is gym.spaces.dict.Dict:\n",
    "\n",
    "        keys = space.spaces.keys()\n",
    "        \n",
    "        values_list = itertools.product(\n",
    "            *[get_space_list(sub_space) for sub_space in space.spaces.values()]\n",
    "        )\n",
    "\n",
    "        return [\n",
    "            {key: value for key, value in zip(keys, values)}\n",
    "            for values in values_list\n",
    "        ]\n",
    "\n",
    "        return space_list\n",
    "\n",
    "    if type(space) is gym.spaces.tuple.Tuple:\n",
    "        return [\n",
    "            list(element) for element in itertools.product(\n",
    "                *[get_space_list(sub_space) for sub_space in space.spaces]\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    # -------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag = agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.76903342e-15,  1.48381613e-17,  7.35774310e-16, -8.74443689e-18,\n",
       "        1.61539419e-16,  1.10724807e-17,  1.89970456e-18, -3.07927255e-17,\n",
       "       -4.58467036e-17, -9.64873285e-17,  1.83135937e-17, -4.58528130e+00])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ag.Reinforce(0.1,0.9,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
